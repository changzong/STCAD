{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI patent Dynamic Graph Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed file 1.xls\n",
      "processed file 2.xls\n",
      "processed file 3.xls\n",
      "processed file 4.xls\n",
      "processed file 5.xls\n",
      "processed file 6.xls\n",
      "processed file 7.xls\n",
      "processed file 8.xls\n",
      "processed file 9.xls\n",
      "processed file 10.xls\n",
      "processed file 11.xls\n",
      "processed file 12.xls\n",
      "processed file 13.xls\n",
      "processed file 14.xls\n",
      "processed file 15.xls\n",
      "processed file 16.xls\n",
      "processed file 17.xls\n",
      "processed file 18.xls\n",
      "processed file 19.xls\n",
      "processed file 20.xls\n",
      "processed file 21.xls\n",
      "processed file 22.xls\n",
      "processed file 23.xls\n",
      "processed file 24.xls\n",
      "processed file 25.xls\n",
      "processed file 26.xls\n",
      "processed file 27.xls\n",
      "processed file 28.xls\n",
      "processed file 29.xls\n",
      "processed file 30.xls\n",
      "processed file 31.xls\n",
      "processed file 32.xls\n",
      "processed file 33.xls\n",
      "processed file 34.xls\n",
      "processed file 35.xls\n",
      "processed file 36.xls\n",
      "processed file 37.xls\n",
      "processed file 38.xls\n",
      "processed file 39.xls\n",
      "processed file 40.xls\n",
      "processed file 41.xls\n",
      "processed file 42.xls\n",
      "processed file 43.xls\n",
      "processed file 44.xls\n",
      "processed file 45.xls\n",
      "processed file 46.xls\n",
      "processed file 47.xls\n",
      "processed file 48.xls\n",
      "processed file 49.xls\n",
      "processed file 50.xls\n",
      "processed file 51.xls\n",
      "processed file 52.xls\n",
      "processed file 53.xls\n",
      "processed file 54.xls\n",
      "processed file 55.xls\n",
      "processed file 56.xls\n",
      "processed file 57.xls\n",
      "processed file 58.xls\n",
      "processed file 59.xls\n",
      "processed file 60.xls\n",
      "processed file 61.xls\n",
      "processed file 62.xls\n",
      "processed file 63.xls\n",
      "processed file 64.xls\n",
      "processed file 65.xls\n",
      "processed file 66.xls\n",
      "processed file 67.xls\n",
      "processed file 68.xls\n",
      "processed file 69.xls\n",
      "processed file 70.xls\n",
      "processed file 71.xls\n",
      "processed file 72.xls\n",
      "processed file 73.xls\n",
      "processed file 74.xls\n",
      "processed file 75.xls\n",
      "processed file 76.xls\n",
      "processed file 77.xls\n",
      "processed file 78.xls\n",
      "processed file 79.xls\n",
      "processed file 80.xls\n",
      "processed file 81.xls\n",
      "processed file 82.xls\n",
      "processed file 83.xls\n",
      "processed file 84.xls\n",
      "processed file 85.xls\n",
      "processed file 86.xls\n",
      "processed file 87.xls\n",
      "processed file 88.xls\n",
      "processed file 89.xls\n",
      "processed file 90.xls\n",
      "processed file 91.xls\n",
      "processed file 92.xls\n",
      "processed file 93.xls\n",
      "processed file 94.xls\n",
      "processed file 95.xls\n",
      "processed file 96.xls\n",
      "processed file 97.xls\n",
      "processed file 98.xls\n",
      "processed file 99.xls\n",
      "processed file 100.xls\n",
      "processed file 101.xls\n",
      "processed file 102.xls\n",
      "processed file 103.xls\n",
      "processed file 104.xls\n",
      "processed file 105.xls\n",
      "processed file 106.xls\n",
      "processed file 107.xls\n",
      "processed file 108.xls\n",
      "processed file 109.xls\n",
      "processed file 110.xls\n",
      "processed file 111.xls\n",
      "processed file 112.xls\n",
      "processed file 113.xls\n",
      "processed file 114.xls\n",
      "processed file 115.xls\n",
      "processed file 116.xls\n",
      "processed file 117.xls\n",
      "processed file 118.xls\n",
      "processed file 119.xls\n",
      "processed file 120.xls\n",
      "processed file 121.xls\n",
      "processed file 122.xls\n",
      "processed file 123.xls\n",
      "processed file 124.xls\n",
      "processed file 125.xls\n",
      "processed file 126.xls\n",
      "processed file 127.xls\n",
      "processed file 128.xls\n",
      "processed file 129.xls\n",
      "processed file 130.xls\n",
      "processed file 131.xls\n",
      "processed file 132.xls\n",
      "processed file 133.xls\n",
      "processed file 134.xls\n",
      "processed file 135.xls\n",
      "processed file 136.xls\n",
      "processed file 137.xls\n"
     ]
    }
   ],
   "source": [
    "# Read global AI patents from local files (2002-2022)\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "all_patents = []\n",
    "pubdate_dict = {}\n",
    "citation_triples = {}\n",
    "cpc_triples = {}\n",
    "raw_file_path = '/Users/zongchang/OneDrive/1-知识计算引擎-2030项目/10-数据集/Patent-AI/'\n",
    "for i in range(137):\n",
    "    df = pd.read_excel(raw_file_path+str(i+1)+'.xls')\n",
    "    df = df[['公开（公告）号', '被引证专利', 'CPC', '公开（公告）日', '摘要', '摘要（翻译）', '标题']]\n",
    "    df.rename(columns = {'公开（公告）号':'pubid', '被引证专利':'citedby', 'CPC': 'cpc', '公开（公告）日': 'pubdate', '摘要':'abstract', '摘要（翻译）': 'abstract_trans', '标题': 'title'}, inplace = True)\n",
    "    df_json = df.to_json(orient ='records', force_ascii=False)\n",
    "    patent_json = json.loads(df_json)\n",
    "    for item in patent_json:\n",
    "        tmp = {'pubid': item['pubid'], 'pubdate': item['pubdate']/1000, 'abstract': item['abstract'], 'abstract_trans': item['abstract_trans'], 'title': item['title']}\n",
    "        if item['citedby']:\n",
    "            tmp['citedby'] = item['citedby'].split('; ')\n",
    "        else:\n",
    "            tmp['citedby'] = []\n",
    "        if item['cpc']:\n",
    "            tmp['cpc'] = item['cpc'].split('; ')\n",
    "        else:\n",
    "            tmp['cpc'] = []\n",
    "        all_patents.append(tmp)\n",
    "        # process publication date\n",
    "        public_date = time.strftime(\"%Y-%m-%d\", time.localtime(item['pubdate']))\n",
    "        if public_date in pubdate_dict:\n",
    "            pubdate_dict[public_date].append(item['pubid'])\n",
    "        else:\n",
    "            pubdate_dict[public_date] = [item['pubid']]\n",
    "        # process citation relations\n",
    "        if item['citedby']:\n",
    "            cite_list = item['citedby'].split('; ')\n",
    "            citation_triples[item['pubid']] = cite_list\n",
    "        # process cpc relations\n",
    "        if item['cpc']:\n",
    "            cpc_list = item['cpc'].split('; ')\n",
    "            cpc_triples[item['pubid']] = cpc_list\n",
    "    print('processed file ' + str(i+1) + '.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all patents after public time t\n",
    "patent_target = []\n",
    "for patent in all_patents:\n",
    "    # later than 2022-01-01\n",
    "    if patent['pubdate'] >= 1640966400:\n",
    "        patent_target.append((patent['pubid'], patent['pubdate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patent_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all cpc co-occurrence edges after time t\n",
    "import itertools\n",
    "\n",
    "edges_dict = {}\n",
    "for patent_date in patent_target:\n",
    "    # only consider top 3 cpc code to limit the edge size\n",
    "    cpc_pairs = list(itertools.combinations(cpc_triples[patent_date[0]][:3], 2))\n",
    "    for pair in cpc_pairs:\n",
    "        tmp1 = (pair[0], pair[1], patent_date[1])\n",
    "        tmp2 = (pair[1], pair[0], patent_date[1])\n",
    "        if tmp1 not in edges_dict and tmp2 not in edges_dict:\n",
    "            edges_dict[tmp1] = 1\n",
    "        elif tmp1 in edges_dict:\n",
    "            edges_dict[tmp1] += 1\n",
    "        else:\n",
    "            edges_dict[tmp2] += 1\n",
    "edges = []\n",
    "for k, v in edges_dict.items():\n",
    "    edges.append((k[0], k[1], v, k[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249252"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give id to each cpc node\n",
    "cpc_ids = {}\n",
    "node_id = 1\n",
    "for edge in edges:\n",
    "    if edge[0] not in cpc_ids:\n",
    "        cpc_ids[edge[0]] = node_id\n",
    "        node_id += 1\n",
    "    if edge[1] not in cpc_ids:\n",
    "        cpc_ids[edge[1]] = node_id\n",
    "        node_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dataset/raw/ai-patent', 'w') as f:\n",
    "    for edge in edges:\n",
    "        f.write(str(cpc_ids[edge[0]])+' '+str(cpc_ids[edge[1]])+' '+str(edge[2])+' '+str(edge[3])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18498"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(cpc_ids.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G06F16/3329\n"
     ]
    }
   ],
   "source": [
    "for k, v in cpc_ids.items():\n",
    "    if v == 1052:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIH-NCI Dynamic Graph Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 0 files\n",
      "processed 1 files\n",
      "processed 2 files\n",
      "processed 3 files\n",
      "processed 4 files\n",
      "processed 5 files\n",
      "processed 6 files\n",
      "processed 7 files\n",
      "processed 8 files\n",
      "processed 9 files\n",
      "processed 10 files\n",
      "processed 11 files\n",
      "processed 12 files\n",
      "processed 13 files\n",
      "processed 14 files\n",
      "processed 15 files\n",
      "processed 16 files\n",
      "processed 17 files\n",
      "processed 18 files\n",
      "processed 19 files\n"
     ]
    }
   ],
   "source": [
    "# Read NCI projects from local files (2002-2021)\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "raw_file_path = '/Users/zongchang/OneDrive/1-知识计算引擎-2030项目/10-数据集/Funding-NIH/'\n",
    "all_projects = []\n",
    "for i in range(20):\n",
    "    df = pd.read_excel(raw_file_path+'NIH-NCI-'+str(2002+i)+'.xlsx')\n",
    "    df = df[['Project Terms', 'Project Title', 'Award Notice Date', 'Application ID', 'Organization Name', 'Organization Country', 'Total Cost', 'Project Abstract']]\n",
    "    df_json = df.to_json(orient ='records', force_ascii=False)\n",
    "    patent_json = json.loads(df_json)\n",
    "    for item in patent_json:\n",
    "        tmp = {'title': item['Project Title'], 'app_id': item['Application ID'], 'org_name': item['Organization Name'], 'country': item['Organization Country'], 'cost': item['Total Cost'], 'abstract':item['Project Abstract']}\n",
    "        if item['Project Terms']:\n",
    "            tmp['keywords'] = [k.strip().lower() for k in item['Project Terms'].split(';')]\n",
    "        if item['Award Notice Date']:\n",
    "            timeArray = time.strptime(item['Award Notice Date'], \"%m/%d/%Y\")\n",
    "            tmp['notice_date'] = int(time.mktime(timeArray))\n",
    "        all_projects.append(tmp)\n",
    "    print('processed '+str(i)+' files')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Operations support for the NCI at Frederick Campus within the fence at Fort Detrick',\n",
       "  'app_id': 10329812,\n",
       "  'org_name': 'NATIONAL CANCER INSTITUTE',\n",
       "  'country': 'UNITED STATES',\n",
       "  'cost': 6660581.0,\n",
       "  'abstract': 'This IAA funds costs to operate the NCI at Frederick Campus within the fence at Fort Detrick.',\n",
       "  'keywords': ['funding',\n",
       "   'maintenance',\n",
       "   'poaceae',\n",
       "   'training',\n",
       "   'water',\n",
       "   'cost',\n",
       "   'operation']},\n",
       " {'title': 'NCI Early Detection Research Network: Biomarker Reference and Resource Center (BRRC)',\n",
       "  'app_id': 10506456,\n",
       "  'org_name': 'NATIONAL CANCER INSTITUTE',\n",
       "  'country': 'UNITED STATES',\n",
       "  'cost': 800000.0,\n",
       "  'abstract': 'The purpose of this IAA is to obtain diagnostic services from Pacific Northwest National Laboratory (PNNL), Department of Energy (DOE) to support the Early Detection Research Network’s (EDRN) efforts to prioritize, verify and validate candidate biomarkers for cancer early detection, diagnosis and early prognosis. The laboratory, herein Biomarkers Reference and Resource Laboratory (BRCC), will serve as a diagnostic core and will measure the candidate biomarkers in specimens provided by the EDRN using antibody free quantitative assays such as Liquid Chromatography - Selected Reaction Monitoring Mass Spectrometry (LC-SRM-MS) and Parallel Reaction Monitoring Mass Spectrometry PRM-MS. The initial work will focus on measuring EDRN candidate biomarkers in prostate cancer specimens (tissue, plasma, serum and urine). However, the measurements will be later extended to include additional candidate biomarkers for cancers supported by the EDRN including cancers of the bladder, pancreas, liver, colon, lung, breast and ovaries. Currently, the limit of detection of a serum or plasma or urine biomarker, using high-pressure high-resolution separation coupled with intelligent selection and multiplexing (PRISM) LC-SRM-MS, is ~50 pg/mL and limit of detection of a tissue biomarker is ~2 amol/µg of tumor tissue.',\n",
       "  'keywords': ['antibodies',\n",
       "   'biological assay',\n",
       "   'biological markers',\n",
       "   'colon carcinoma',\n",
       "   'coupled',\n",
       "   'department of energy',\n",
       "   'diagnosis',\n",
       "   'diagnostic',\n",
       "   'diagnostic services',\n",
       "   'early detection research network',\n",
       "   'intelligence',\n",
       "   'laboratories',\n",
       "   'liquid chromatography',\n",
       "   'malignant neoplasm of liver',\n",
       "   'malignant neoplasm of lung',\n",
       "   'malignant neoplasm of ovary',\n",
       "   'malignant neoplasm of pancreas',\n",
       "   'malignant neoplasm of prostate',\n",
       "   'malignant neoplasm of urinary bladder',\n",
       "   'mass spectrum analysis',\n",
       "   'measurement',\n",
       "   'measures',\n",
       "   'monitor',\n",
       "   'pacific northwest',\n",
       "   'plasma',\n",
       "   'prognosis',\n",
       "   'reaction',\n",
       "   'resolution',\n",
       "   'resources',\n",
       "   'screening for cancer',\n",
       "   'serum',\n",
       "   'specimen',\n",
       "   'tissues',\n",
       "   'tumor tissue',\n",
       "   'urine',\n",
       "   'work',\n",
       "   'cancer biomarkers',\n",
       "   'candidate marker',\n",
       "   'detection limit',\n",
       "   'malignant breast neoplasm',\n",
       "   'pressure',\n",
       "   'tissue biomarkers']},\n",
       " {'title': None,\n",
       "  'app_id': 10504766,\n",
       "  'org_name': 'NATIONAL CANCER INSTITUTE',\n",
       "  'country': 'UNITED STATES',\n",
       "  'cost': 125000.0,\n",
       "  'abstract': 'No abstract available'},\n",
       " {'title': 'Pediatric Cancer Data Commons Harmonization',\n",
       "  'app_id': 10514850,\n",
       "  'org_name': 'NATIONAL CANCER INSTITUTE',\n",
       "  'country': 'UNITED STATES',\n",
       "  'cost': 841407.0,\n",
       "  'abstract': 'Pediatric cancer research data availability and access is limited due to the rarity of pediatric cancers. To assist in overcoming these difficulties, the Pediatric Cancer Data Commons (PCDC) collects, aggregates, and makes available pediatric cancer research data for use by the research community. This data commons is a resource for collections of information related to clinical trials that is connected to other data sources in a cloud-based environment with associated data use tools. This effort will improve collection, access to, and use of pediatric cancer data and increase the effectiveness of research efforts and improve patient outcomes. This effort directly supports Childhood Cancer Data Initiative (CCDI) to increase research capabilities to develop improved pediatric therapies with the goal of reducing the incidence of and curing cancer. The objective of this project is to acquire program and technical informatics support services for clinical research data harmonization and integration; establishing infrastructure; data transfer and migration from multiple specialized databases; data quality assessment and assurance; and acquire required program management support.',\n",
       "  'keywords': ['childhood',\n",
       "   'clinical research',\n",
       "   'clinical trials',\n",
       "   'collection',\n",
       "   'communities',\n",
       "   'data',\n",
       "   'data commons',\n",
       "   'data sources',\n",
       "   'databases',\n",
       "   'environment',\n",
       "   'goals',\n",
       "   'incidence',\n",
       "   'informatics',\n",
       "   'infrastructure',\n",
       "   'malignant childhood neoplasm',\n",
       "   'malignant neoplasms',\n",
       "   'patient-focused outcomes',\n",
       "   'research',\n",
       "   'resources',\n",
       "   'services',\n",
       "   'anticancer research',\n",
       "   'cloud based',\n",
       "   'data exchange',\n",
       "   'data harmonization',\n",
       "   'data integration',\n",
       "   'data quality',\n",
       "   'effectiveness research',\n",
       "   'improved',\n",
       "   'migration',\n",
       "   'programs',\n",
       "   'tool']},\n",
       " {'title': 'Childhood Cancer Data Initiative Program Support              ',\n",
       "  'app_id': 10514855,\n",
       "  'org_name': 'NATIONAL CANCER INSTITUTE',\n",
       "  'country': 'UNITED STATES',\n",
       "  'cost': 123658.0,\n",
       "  'abstract': 'The Childhood Cancer Data Initiative (CCDI) is an NCI program which collects, analyzes, and shares data to address cancer in children, adolescents, and young adults. The initiative intends to integrate new and existing data sources into a broader research ecosystem. The objective of the CCDI is to ensure that data from each of the 16,000 children and adolescents diagnosed with cancer in the United States each year contributes to reducing the burden of this disease. The success of the CCDI is predicated upon many factors, including making use of comprehensive, well integrated information systems into which data will be collected, processed and harmonized, and from which they will be distributed. The information systems identified to support the CCDI include those within the Cancer Research Data Commons (CRDC) rubric and the Moonshot’s nascent National Cancer Data Ecosystem. The planning efforts for the CCDI require acknowledging the lessons learned from prior NCI systems holding cancer phenome and genome data, understanding modern architectures of research information systems capable of managing such data, and knowledge of the landscape of such systems currently in use and under development at NCI. A variety of subject matter expertise is needed to guide and support CCDI-related activities, including biomedical informatics expertise, clinical expertise in childhood and adolescent cancers, technical, and project management expertise to support CCDI efforts.',\n",
       "  'keywords': ['address',\n",
       "   'adolescent',\n",
       "   'adolescent and young adult',\n",
       "   'architecture',\n",
       "   'child',\n",
       "   'childhood',\n",
       "   'clinical',\n",
       "   'data',\n",
       "   'data commons',\n",
       "   'data sources',\n",
       "   'development',\n",
       "   'diagnosis',\n",
       "   'ecosystem',\n",
       "   'ensure',\n",
       "   'genome',\n",
       "   'information systems',\n",
       "   'knowledge',\n",
       "   'malignant childhood neoplasm',\n",
       "   'malignant neoplasms',\n",
       "   'modernization',\n",
       "   'process',\n",
       "   'research',\n",
       "   'system',\n",
       "   'united states',\n",
       "   'anticancer research',\n",
       "   'biomedical informatics',\n",
       "   'burden of illness',\n",
       "   'data ecosystem',\n",
       "   'data sharing',\n",
       "   'phenome',\n",
       "   'programs',\n",
       "   'success']},\n",
       " {'title': 'Precision Medicine Initiative Collaboration',\n",
       "  'app_id': 10363606,\n",
       "  'org_name': 'NATIONAL CANCER INSTITUTE',\n",
       "  'country': 'UNITED STATES',\n",
       "  'cost': 3461226.0,\n",
       "  'abstract': '\"The Presidential Precision Medicine Initiative (PMI) directs the National Cancer Institute (NCI), a component of the National Institute of Health, which is part of the Department of Health and Human Services, to accelerate the design and testing of effective, tailored treatments for cancer while developing the infrastructure that will be needed to support next generation cancer research.\\n\\nNCI, as a component of the National Institutes of Health (NIH) and a Broad Deployment Agency for National Strategic Computing Initiative (NSCI), possessing an outstanding cancer biology and oncology knowledge base, extensive research and programmatic infrastructure, complex biological systems and scientific application development expertise, seeks to significantly improve the detection, diagnosis, treatment, and prevention of cancer through the introduction of high performance computational capabilities and advanced predictive modeling to the cancer research community. Now, therefore, the Parties intend to collaborate through steering committees, working groups, and project teams to develop strategic plans, set priorities, and leverage resources and expertise from multiple sources, including the private sector, toward the goal of collaborative development of a shared technology ecosystem and targeted applications that will bring advanced computing capability to biological research and produce a transformation in drug and treatment development and, ultimately, in patient care and outcomes.\\nThis MOU sets forth the framework for the collaboration between the Parties and for pursuing specific collaborative projects. This may involve additional parties and will be implemented through separate agreements, as needed.\\n\"',\n",
       "  'keywords': ['agreement',\n",
       "   'cancer biology',\n",
       "   'collaborations',\n",
       "   'communities',\n",
       "   'detection',\n",
       "   'development',\n",
       "   'diagnosis',\n",
       "   'ecosystem',\n",
       "   'goals',\n",
       "   'infrastructure',\n",
       "   'national cancer institute',\n",
       "   'oncology',\n",
       "   'patient care',\n",
       "   'performance',\n",
       "   'precision medicine initiative',\n",
       "   'private sector',\n",
       "   'research',\n",
       "   'resources',\n",
       "   'source',\n",
       "   'strategic planning',\n",
       "   'technology',\n",
       "   'testing',\n",
       "   'united states dept. of health and human services',\n",
       "   'united states national institutes of health',\n",
       "   'anticancer research',\n",
       "   'biological research',\n",
       "   'cancer prevention',\n",
       "   'cancer therapy',\n",
       "   'care outcomes',\n",
       "   'complex biological systems',\n",
       "   'design',\n",
       "   'drug development',\n",
       "   'improved',\n",
       "   'individualized medicine',\n",
       "   'knowledge base',\n",
       "   'next generation',\n",
       "   'predictive modeling',\n",
       "   'therapy development',\n",
       "   'working group']},\n",
       " {'title': 'NCIP HUB Maintenance and Hosting',\n",
       "  'app_id': 10498028,\n",
       "  'org_name': 'NATIONAL CANCER INSTITUTE',\n",
       "  'country': 'UNITED STATES',\n",
       "  'cost': 102155.0,\n",
       "  'abstract': 'o_x0009_Abstract:  The National Cancer Institute (NCI), a major biomedical research institute within the National Institutes of Health (NIH), coordinates the nation’s research program on cancer prevention, detection, diagnosis, treatment, rehabilitation, survivorship and control. As a result of the 1971 National Cancer Act legislation, the NCI has built a research community that includes regional and community cancer centers, physicians who are cancer specialists, cooperative groups of clinical researchers, and volunteer and community outreach groups. NCI also has initiated cancer control programs to hasten the application of knowledge gained through cancer research.',\n",
       "  'keywords': ['biomedical research',\n",
       "   'cancer center',\n",
       "   'cancer control',\n",
       "   'clinical trials cooperative group',\n",
       "   'communities',\n",
       "   'community outreach',\n",
       "   'contracts',\n",
       "   'detection',\n",
       "   'diagnosis',\n",
       "   'documentation',\n",
       "   'health insurance portability and accountability act',\n",
       "   'knowledge',\n",
       "   'maintenance',\n",
       "   'malignant neoplasms',\n",
       "   'national cancer institute',\n",
       "   'physicians',\n",
       "   'rehabilitation therapy',\n",
       "   'research',\n",
       "   'research institute',\n",
       "   'research personnel',\n",
       "   'services',\n",
       "   'specialist',\n",
       "   'statutes and laws',\n",
       "   'technical degree',\n",
       "   'testing',\n",
       "   'united states national institutes of health',\n",
       "   'anticancer research',\n",
       "   'cancer prevention',\n",
       "   'programs',\n",
       "   'survivorship',\n",
       "   'volunteer']},\n",
       " {'title': 'DOE Collaboration in support of Expand Data Commons and Data Sharing',\n",
       "  'app_id': 10498035,\n",
       "  'org_name': 'NATIONAL CANCER INSTITUTE',\n",
       "  'country': 'UNITED STATES',\n",
       "  'cost': 648091.0,\n",
       "  'abstract': '\\uf0a7_x0009_The Center for Cancer Data Harmonization (CCDH) will create a national Cancer Data Ecosystem that will enable participants across the cancer research and care spectrum to contribute, access, combine and analyze diverse data that will enable new discoveries and ultimately reduce the personal and public health burden of cancer. To support this, the CCDH will enable data collection, deposition, harmonization, quality assurance, query, integration, and analytics across an initial set of Cancer Research Data Commons (CRDC) nodes.',\n",
       "  'keywords': ['cancer burden',\n",
       "   'cancer center',\n",
       "   'cancer model',\n",
       "   'collaborations',\n",
       "   'data collection',\n",
       "   'data commons',\n",
       "   'deposition',\n",
       "   'evaluation',\n",
       "   'informatics',\n",
       "   'malignant neoplasms',\n",
       "   'metadata',\n",
       "   'ontology',\n",
       "   'participant',\n",
       "   'public health',\n",
       "   'reporting',\n",
       "   'services',\n",
       "   'terminology',\n",
       "   'update',\n",
       "   'anticancer research',\n",
       "   'cancer care',\n",
       "   'data ecosystem',\n",
       "   'data harmonization',\n",
       "   'data modeling',\n",
       "   'data sharing',\n",
       "   'diverse data',\n",
       "   'quality assurance',\n",
       "   'tool',\n",
       "   'web interface']},\n",
       " {'title': 'Metadata Development, Curation, Harmonization and Program Support',\n",
       "  'app_id': 10498048,\n",
       "  'org_name': 'NATIONAL CANCER INSTITUTE',\n",
       "  'country': 'UNITED STATES',\n",
       "  'cost': 2262879.0,\n",
       "  'abstract': '\\uf0a7_x0009_The purpose of this Statement of Work (SOW) is to supply specialized metadata development, curation, harmonization and program support on behalf of the National Institutes of Health (NIH), National Cancer Institute (NCI), Center for Biomedical Informatics and Information Technology (CBIIT) Metadata Content Development Team in its support of NCI IT and biomedical informatics coordination and management efforts.',\n",
       "  'keywords': ['adherence',\n",
       "   'business rules',\n",
       "   'collection',\n",
       "   'communities',\n",
       "   'computer software',\n",
       "   'contractor',\n",
       "   'development',\n",
       "   'feedback',\n",
       "   'information technology',\n",
       "   'infrastructure',\n",
       "   'knowledge',\n",
       "   'mentorship',\n",
       "   'metadata',\n",
       "   'methodology',\n",
       "   'modeling',\n",
       "   'national cancer institute',\n",
       "   'reporting',\n",
       "   'semantics',\n",
       "   'services',\n",
       "   'structure',\n",
       "   'terminology',\n",
       "   'training',\n",
       "   'united states national institutes of health',\n",
       "   'work',\n",
       "   'biomedical informatics',\n",
       "   'curriculum development',\n",
       "   'data quality',\n",
       "   'data repository',\n",
       "   'data standards',\n",
       "   'improved',\n",
       "   'member',\n",
       "   'metadata standards',\n",
       "   'next generation',\n",
       "   'programs',\n",
       "   'repository',\n",
       "   'skill acquisition',\n",
       "   'usability']},\n",
       " {'title': 'Diet-Genetic Interactions – Metabolic Pathways Influenced by Intake of Dietary Compounds',\n",
       "  'app_id': 10506441,\n",
       "  'org_name': 'NATIONAL CANCER INSTITUTE',\n",
       "  'country': 'UNITED STATES',\n",
       "  'cost': 181500.0,\n",
       "  'abstract': 'The primary purpose of this research is to determine if smokers have higher levels of beta-apo-13-carotenone than nonsmokers or former smokers. This Inter-Agency Agreement will capitalize on the joint expertise of the NCI DCP NSRG and the USDA Beltsville Human Nutrition Research Center to conduct human research related to the role of diet in cancer prevention.\\n\\nThe USDA aims to analyze the blood of smokers obtained from commercial and other sources (such as Prostate Lung Colon Ovarian Screening, ATBC, and CARET Trials) to examine and corroborate the findings in preclinical models. The testing hypothesis is that smokers will have a higher concentration of beta-apo-13-carotenone than non- or former smokers. \\nThe methods and standards are available to USDA and the team is fully equipped to do these analyses that are a natural follow-up to the published studies on healthy non-smoker. The identification of the elevated formation of beta-apo-13-carotenone in smokers but not in normal nonsmoking subjects will help explain the unexpected lung cancer increase in previous trials (the beta-carotene blood levels in smokers in these trials were orders of magnitude higher than the normal physiological range).\\n\\nUSDA will obtain standards and adapt the novel methodology for analysis of beta-apo-13-carotenone by LC-MS/MS. Once the method is vetted, USDA will obtain blood from smokers, either through commercial sources or other sources. Carotenoids and metabolites will be extracted from plasma samples by liquid-liquid extraction, and the resulting extract will be concentrated then injected onto an Agilent 6490 liquid chromatograph with a triple quadrupole mass spectrometer detector fitted with an atmospheric pressure chemical ionization source for measurement of beta-apo-13-carotenone. The same extract will also be injected onto an HPLC with a photodiode array detector for analysis of carotenoids and vitamin A. Both instruments will be fitted with a C30 reverse phase HPLC column, which will provide maximum separation of the carotenoid species and analytes, and separation will be achieved with a gradient mobile phase comprised of methanol, water, and methyl tertiary butyl ether. Analyte concentrations will be determined against an external standard curve. Resulting carotenoid and beta-apo-13-carotenone concentrations in plasma of smokers and nonsmokers will be compared.',\n",
       "  'keywords': ['agreement',\n",
       "   'atmospheric pressure',\n",
       "   'beta carotene',\n",
       "   'blood',\n",
       "   'carotenoids',\n",
       "   'chemicals',\n",
       "   'colon',\n",
       "   'diet',\n",
       "   'dietary intake',\n",
       "   'ethers',\n",
       "   'genetic',\n",
       "   'high pressure liquid chromatography',\n",
       "   'human',\n",
       "   'joints',\n",
       "   'liquid substance',\n",
       "   'lung',\n",
       "   'malignant neoplasm of lung',\n",
       "   'measurement',\n",
       "   'metabolic pathway',\n",
       "   'methanol',\n",
       "   'methodology',\n",
       "   'methods',\n",
       "   'nutritional study',\n",
       "   'ovarian',\n",
       "   'phase',\n",
       "   'physiological',\n",
       "   'plasma',\n",
       "   'pre-clinical model',\n",
       "   'prostate',\n",
       "   'publishing',\n",
       "   'research',\n",
       "   'role',\n",
       "   'sampling',\n",
       "   'smoker',\n",
       "   'source',\n",
       "   'testing',\n",
       "   'vitamin a',\n",
       "   'water',\n",
       "   'cancer prevention',\n",
       "   'detector',\n",
       "   'follow-up',\n",
       "   'former smoker',\n",
       "   'instrument',\n",
       "   'ionization',\n",
       "   'mass spectrometer',\n",
       "   'non-smoker',\n",
       "   'non-smoking',\n",
       "   'novel',\n",
       "   'screening']}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_projects[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_date = []\n",
    "for item in all_projects:\n",
    "    if 'keywords' in item and 'notice_date' in item:\n",
    "        # later than 2020-01-01\n",
    "        if item['notice_date'] >= 1577808000:\n",
    "            if len(item['keywords']) > 5:\n",
    "                keyword_date.append([item['keywords'][:5], item['notice_date']])\n",
    "            else:\n",
    "                keyword_date.append([item['keywords'], item['notice_date']])\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21542"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keyword_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_dict = {} \n",
    "idx = 1\n",
    "for item in keyword_date:\n",
    "    for keyword in item[0]:\n",
    "        if keyword not in keyword_dict:\n",
    "            keyword_dict[keyword] = idx\n",
    "            idx += 1\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2339"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(keyword_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all keyword co-occurrence edges after time t\n",
    "import itertools\n",
    "\n",
    "edges_dict = {}\n",
    "for item in keyword_date:\n",
    "    keyword_pairs = list(itertools.combinations(item[0], 2))\n",
    "    for pair in keyword_pairs:\n",
    "        tmp1 = (keyword_dict[pair[0]], keyword_dict[pair[1]], item[1])\n",
    "        tmp2 = (keyword_dict[pair[1]], keyword_dict[pair[0]], item[1])\n",
    "        if tmp1 not in edges_dict and tmp2 not in edges_dict:\n",
    "            edges_dict[tmp1] = 1\n",
    "        elif tmp1 in edges_dict:\n",
    "            edges_dict[tmp1] += 1\n",
    "        else:\n",
    "            edges_dict[tmp2] += 1\n",
    "edges = []\n",
    "for k, v in edges_dict.items():\n",
    "    edges.append((k[0], k[1], v, k[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185717"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dataset/raw/nci-project', 'w') as f:\n",
    "    for edge in edges:\n",
    "        f.write(str(edge[0])+' '+str(edge[1])+' '+str(edge[2])+' '+str(edge[3])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "award\n"
     ]
    }
   ],
   "source": [
    "for k, v in keyword_dict.items():\n",
    "    if v == 120:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breast epithelial cells\n"
     ]
    }
   ],
   "source": [
    "for k, v in keyword_dict.items():\n",
    "    if v == 1177:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting nodes and edges number for each dataset\n",
    "nodes = {}\n",
    "edges = {}\n",
    "with open('../dataset/raw/uci', 'r') as f:\n",
    "    for line in f.readlines()[2:]:\n",
    "        items = line.split(' ')\n",
    "        if items[0] not in nodes:\n",
    "            nodes[items[0]] = 1\n",
    "        if items[1] not in nodes:\n",
    "            nodes[items[1]] = 1\n",
    "        if (items[0], items[1], items[3]) not in edges:\n",
    "            edges[(items[0], items[1], items[3])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1899"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(nodes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59798"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
